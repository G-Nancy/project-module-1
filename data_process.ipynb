{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gnancy/.pyenv/versions/3.9.2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "import json\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_taken_exif(path):\n",
    "    exif = Image.open(path).getexif()\n",
    "    if not exif:\n",
    "        raise Exception(f\"Image {path} doesn't have EXIF data \")\n",
    "\n",
    "def get_date_taken_name(path):\n",
    "    dt = re.search(r\"(\\d{8})\", path)\n",
    "    if dt: # Check if a match was found\n",
    "        extracted_date = dt.group(1)  # Get the captured group (the digits)\n",
    "        return extracted_date\n",
    "\n",
    "    else: return None\n",
    "    print(extracted_date)\n",
    "\n",
    "def img_details(filepath):\n",
    "    img = Image.open(filepath)\n",
    "    # width, height= img.size\n",
    "    img_nm = filepath\n",
    "    img_size = os.path.getsize(filepath)\n",
    "    img_dt =get_date_taken_name(filepath)\n",
    "    return img_nm, img_size, img_dt\n",
    "\n",
    "# get_date_taken_name('Food/image(30).jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No API key provided.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the Gemini Pro Vision model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "def configure_api_key():\n",
    "    \"\"\"Prompts the user for the Gemini API key and configures it.\"\"\"\n",
    "    api_key = input(\"Please enter your Gemini API key: \")\n",
    "\n",
    "    if api_key:\n",
    "        os.environ[\"GEMINI_API_KEY\"] = api_key  # Set the environment variable\n",
    "        genai.configure(api_key=api_key)\n",
    "        print(\"Gemini API key configured for this session.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Error: No API key provided.\")\n",
    "        return False\n",
    "\n",
    "# Call the configuration function\n",
    "if configure_api_key():\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_food_image(image_path,model):\n",
    "    \"\"\"\n",
    "    Analyzes a food image using the Gemini Pro Vision model and generates features\n",
    "    based on a detailed prompt.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text response from the Gemini model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_nm, img_size, img_dt=img_details(image_path)\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a food analyst and you have collected a bunch of pictures on which you want to collect food intake patterns for:\n",
    "        Understand Dietary Patterns and Habits: Identify and analyze dietary patterns, habits, and trends from the food image data to gain insights into eating behaviors\n",
    "        Explore Factors Influencing Food Choices: Investigate factors influencing food choices, such as cuisine type, meal location, mood, and dietary restrictions\n",
    "        Explore Dietary Diversity\n",
    "        Investigate the Impact of Food Choices on Mood\n",
    "\n",
    "        Goal: You want to create a dataframe for all images with each row for one image and corresponding features as columns in the dataframe with columns e.g. image_name, image_date(use it from image name or null), image_size, features e.g. Cuisine, salt, sugar etc.\n",
    "\n",
    "        Analyze the following food image and generate the following features, adhering strictly to the specified possible values:\n",
    "\n",
    "        *   Cuisine: (Description: The likely cuisine or culinary style of the dish. Possible Values: Thai, Indian, Italian, Mexican, American, Fusion, Combination, Unknown)\n",
    "        *   Happiness_Level (1-5): (Description: A subjective rating of how appealing or satisfying the meal appears. Possible Values: Integer scale from 1 (lowest) to 5 (highest))\n",
    "        *   Meal_Course: (Description: The part of the meal represented by the dish. Possible Values: Starter, Main Course, Side Dish, Dessert, Snack, Drink, Unknown)\n",
    "        *   Sugar (High/Medium/Low): (Description: A relative indication of the sugar content of the meal. Possible Values: High, Medium, Low, Unknown). If it is a curry then sugar is low.\n",
    "        *   Salt (High/Medium/Low): (Description: A relative indication of the salt content of the meal. Possible Values: High, Medium, Low, Unknown). If it is a dessert then salt is low, if its curry then medium\n",
    "        *   Healthy: (Description: A subjective assessment of the overall healthfulness of the meal. Possible Values: Yes, No, Unknown, healthy, unhealthy, balanced, carb-heavy, protein-rich)\n",
    "        *   Processing_level: (Description: Subjective assessment of how processed the food is. Possible Values: Unprocessed, Minimally Processed, Processed, Highly Processed)\n",
    "        *   Preparation_Method: (Description: How the food was prepared. Possible Values: Fried, Baked, Grilled, Steamed, Raw)\n",
    "        *   Dominant_Color: (Description: The most prominent color in the dish. Possible Values: Red, Green, Yellow, Brown, White, etc.)\n",
    "        *   Food_Diversity: (Description: A measure of how many different types of food are present in the meal. Possible Values: High, Medium, Low)\n",
    "\n",
    "        Provide your response in a clear, concise format, listing each feature and its value in a dictionary format with key columns as [name:{img_nm}, size:{img_size}, date:{img_dt},Cuisine,Happiness_Level,Meal_Course,Sugar, Healthy, Processing_level,Preparation_Method,  Dominant_Color, Food_Diversity] \n",
    "        \"\"\"\n",
    "\n",
    "        response = model.generate_content([prompt, img])\n",
    "        # return response.text\n",
    "        response_text = response.text\n",
    "        # Extract the dictionary string using regex\n",
    "        match = re.search(r'\\{(.+)\\}', response_text, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "          dict_string = match.group(0)\n",
    "          # Clean the dictionary string\n",
    "          # 1. Replace keys with double quotes\n",
    "          cleaned_dict_string = re.sub(r\"'(\\w+)':\", r'\"\\1\":', dict_string)\n",
    "          # 2. Replace values with double quotes if are string\n",
    "          cleaned_dict_string = re.sub(r\":\\s*'([^']*)'\", r':\"\\1\"', cleaned_dict_string)\n",
    "          # 3. Replace None to null\n",
    "          cleaned_dict_string = cleaned_dict_string.replace(\"None\", \"null\")\n",
    "          # 4. Convert date to string before loading\n",
    "          cleaned_dict_string = re.sub(r'\"date\":\\s*(\\d+)', r'\"date\": \"\\1\"', cleaned_dict_string)\n",
    "          # 5. Remove comments\n",
    "          cleaned_dict_string = re.sub(r'\\s*#.*', '', cleaned_dict_string)\n",
    "          try:\n",
    "            data_dict = json.loads(cleaned_dict_string)\n",
    "            data_dict[\"name\"]=img_nm\n",
    "            data_dict[\"size\"]=img_size\n",
    "            data_dict[\"date\"]=img_dt\n",
    "            return data_dict\n",
    "          except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e} in:\\n{cleaned_dict_string}\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Error: Could not extract dictionary from: {response_text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error ocurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM API calls on image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_llm_gen(path):\n",
    "    for filename in os.listdir(path):\n",
    "        img_data =[]\n",
    "        if filename.endswith(('.png','.jpg','.jpeg')):\n",
    "            filepath = os.path.join(path,filename )\n",
    "            analysis_result = analyze_food_image(filepath)\n",
    "            img_data.append(analysis_result)\n",
    "    return img_data\n",
    "\n",
    "\n",
    "def analyze_all_images_in_folder(folder_path, model):\n",
    "    \"\"\" Analyzes all images in a folder and returns a list of dictionaries.\"\"\"\n",
    "    all_results = []\n",
    "    if not os.path.exists(folder_path):\n",
    "      print(f\"Error: {folder_path} does not exist.\")\n",
    "      return None\n",
    "    if not os.path.isdir(folder_path):\n",
    "      print(f\"Error: {folder_path} is not a directory.\")\n",
    "      return None\n",
    "    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No image files found in {folder_path}\")\n",
    "        return None\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        print(f\"Processing: {image_path}\")\n",
    "        result = analyze_food_image(image_path, model)\n",
    "        if result:\n",
    "            all_results.append(result)\n",
    "        else:\n",
    "            print(f\"Skipping {image_path} due to error.\")\n",
    "    return all_results\n",
    "\n",
    "def write_to_file(img_data, filenm):\n",
    "    \"\"\" Writes a list of dictionaries to a file, one dictionary per line, in JSON format.\"\"\"\n",
    "    try:\n",
    "        with open(filenm, \"w\", encoding=\"utf-8\") as f:\n",
    "            for data_dict in img_data:\n",
    "                data_dict_to_dump = {k: 'null' if v is None else v for k, v in data_dict.items()}\n",
    "                json.dump(data_dict, f)  # Write the dictionary as JSON\n",
    "                f.write('\\n')  # Add a newline after each dictionary\n",
    "        print(f\"Results saved to {filenm}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to file: {e}\")\n",
    "\n",
    "def read_jsonl_to_dataframe(filepath):\n",
    "    \"\"\" Reads a JSON Lines file into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_json(filepath, lines=True, convert_dates=False)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading jsonl to dataframe: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample call to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to output_t.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>date</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Happiness_Level</th>\n",
       "      <th>Meal_Course</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Salt</th>\n",
       "      <th>Healthy</th>\n",
       "      <th>Processing_level</th>\n",
       "      <th>Preparation_Method</th>\n",
       "      <th>Dominant_Color</th>\n",
       "      <th>Food_Diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food/PXL_20250310_172614757.jpg</td>\n",
       "      <td>2177968</td>\n",
       "      <td>20250310</td>\n",
       "      <td>Fusion</td>\n",
       "      <td>4</td>\n",
       "      <td>Main Course</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>healthy</td>\n",
       "      <td>Minimally Processed</td>\n",
       "      <td>Steamed</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name     size      date Cuisine  \\\n",
       "0  Food/PXL_20250310_172614757.jpg  2177968  20250310  Fusion   \n",
       "\n",
       "   Happiness_Level  Meal_Course Sugar    Salt  Healthy     Processing_level  \\\n",
       "0                4  Main Course   Low  Medium  healthy  Minimally Processed   \n",
       "\n",
       "  Preparation_Method Dominant_Color Food_Diversity  \n",
       "0            Steamed         Orange         Medium  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"Food/PXL_20250310_172614757.jpg\" #\"Food/PXL_20250321_101158506.jpg\" #Food/PXL_20240508_100847853.jpg\" #\"Food/PXL_20230114_131406857.jpg\"  # Replace with your image path\n",
    "output_filename = \"output_t.json\"\n",
    "\n",
    "\n",
    "analysis_result = analyze_food_image(image_path,model)\n",
    "dum =[]\n",
    "if analysis_result:\n",
    "    dum.append(analysis_result)\n",
    "    # print(analysis_result)\n",
    "    write_to_file(dum, output_filename)\n",
    "    df = read_jsonl_to_dataframe(output_filename)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder='Food'\n",
    "output_filename = \"llm_output.json\"\n",
    "\n",
    "# Commented to avoid re-execution\n",
    "# all_results =analyze_all_images_in_folder(img_folder, model)\n",
    "# write_to_file(all_results, output_filename)\n",
    "\n",
    "df = read_jsonl_to_dataframe(output_filename)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write file with LLM results\n",
    "\n",
    "Avoid calling APIs again and again as Env variables are lost with environment restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError creating DataFrame or saving to file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m filenm \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 79\u001b[0m extracted_dictionaries \u001b[38;5;241m=\u001b[39m extract_and_clean_dictionaries(\u001b[43mimg_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_data' is not defined"
     ]
    }
   ],
   "source": [
    "def write_to_file(img_data,filenm):\n",
    "    try:\n",
    "        with open(filenm, \"w\") as f:  # Open the file in write mode (\"w\")\n",
    "            for line in img_data:\n",
    "                f.write(line)  # Write each line to the file, \n",
    "                print(\"Results saved to output.txt\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to file: {e}\")\n",
    "        \n",
    "def read_from_file(filenm):\n",
    "    try:\n",
    "        img_data =[]\n",
    "        with open(filenm, \"r\") as f:\n",
    "            # img_data = f.read\n",
    "            ln = f.readlines()\n",
    "            ln_n = [line.strip() for line in ln]\n",
    "            ln_f = ''.join(ln_n)\n",
    "            img_data.append(ln_f)\n",
    "            print(\"Results read from output.txt\")\n",
    "            return img_data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filenm}\")\n",
    "        return None\n",
    "    \n",
    "def extract_and_clean_dictionaries(img_data):\n",
    "    \"\"\"\n",
    "    Extracts, cleans, and parses dictionaries from a list of strings,\n",
    "    Returns:A list of dictionaries, or an empty list if no dictionaries are found.\n",
    "    \"\"\"\n",
    "    all_dictionaries = []\n",
    "    for input_string in img_data:\n",
    "        # 1. Remove print statements\n",
    "        input_string = re.sub(r\"print\\s*\\([^\\)]*\\)\", \"\", input_string)\n",
    "        input_string = input_string.strip() # Removes whitespace\n",
    "\n",
    "\n",
    "        # 2. Find the dictionary with a variable name (food_data = or food_image_features = )\n",
    "        match = re.search(r'(?:[\\w_]+\\s*=\\s*)?({.*?})', input_string, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            dict_string = match.group(1)\n",
    "            # Clean the dictionary string\n",
    "            # 1. Remove comments\n",
    "            cleaned_dict_string = re.sub(r'#.*', '', dict_string)\n",
    "            # 2. Replace None to null\n",
    "            cleaned_dict_string = cleaned_dict_string.replace(\"None\", \"null\")\n",
    "            # 3. Replace keys with double quotes\n",
    "            cleaned_dict_string = re.sub(r\"'(\\w+)':\", r'\"\\1\":', cleaned_dict_string)\n",
    "            # 4. Replace values with double quotes if are string\n",
    "            cleaned_dict_string = re.sub(r\":\\s*'([^']*)'\", r':\"\\1\"', cleaned_dict_string)\n",
    "            # 5. Remove spaces at the begining and end\n",
    "            cleaned_dict_string = cleaned_dict_string.strip()\n",
    "\n",
    "            \n",
    "            try:\n",
    "                data_dict = json.loads(cleaned_dict_string) # Parse JSON\n",
    "                all_dictionaries.append(data_dict)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON after cleaning: {e} in:\\n{cleaned_dict_string}\")\n",
    "        else:\n",
    "           print(f\"No dictionary found in: {input_string}\")\n",
    "\n",
    "    return all_dictionaries\n",
    "\n",
    "\n",
    "def create_dataframe_and_file(dictionaries, filename=\"output.csv\"):\n",
    "    if not dictionaries:\n",
    "        print(\"No dictionaries to create a DataFrame.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(dictionaries)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"DataFrame created and saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame or saving to file: {e}\")\n",
    "\n",
    "filenm = 'output.txt'\n",
    "extracted_dictionaries = extract_and_clean_dictionaries(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failed data cleaning Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m txt_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mimg_data\u001b[49m)\n\u001b[1;32m      2\u001b[0m food_item \u001b[38;5;241m=\u001b[39m txt_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m food_item[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_data' is not defined"
     ]
    }
   ],
   "source": [
    "txt_str = \"\".join(img_data)\n",
    "food_item = txt_str.split(\"}\")\n",
    "food_item[0:2]\n",
    "test_obj = food_item[0]\n",
    "test_obj_v1 =test_obj.split(\"\\n\")\n",
    "# test_obj_v1[0:5]\n",
    "test_obj_v2 =[item for item in test_obj_v1 if \":\" in item]\n",
    "# test_obj_v2\n",
    "\n",
    "def clean_data_str(str):\n",
    "    # return re.findall(r'.*(\\'.*\\'.*\\'.*\\').*',str)\n",
    "    return re.findall(r'.*(\\'.*\\'.*\\'.*\\').*',str)[0].split(\":\")\n",
    "clean_data_str(test_obj_v2[0])\n",
    "\n",
    "def clean_data_obj(obj):\n",
    "    test_obj_v1 =obj.split(\"\\n\")\n",
    "    food_list = []\n",
    "    for item in test_obj_v1:\n",
    "        if \":\" in item:\n",
    "            food_dict = {}\n",
    "            for i in item:\n",
    "                k,v = re.findall(r'.*(\\'.*\\'.*\\'.*\\').*',str)[0].split(\":\")\n",
    "                food_dict[k] = v\n",
    "        food_list.append(food_dict)\n",
    "    return food_list\n",
    "\n",
    "clean_data_str(test_obj_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for item in img_data:\n",
    "    text = item\n",
    "    print(text)\n",
    "    # text = text.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    text = re.sub(r\"^[^\\{]*\\{\", \"{\", text)\n",
    "    text = text.replace('\\n', '').replace(\"```\", \"\").replace(' ', '').strip()\n",
    "    # text = json.load(text)\n",
    "    print(text)\n",
    "\n",
    "write_to_file(text, 'output_clean.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
